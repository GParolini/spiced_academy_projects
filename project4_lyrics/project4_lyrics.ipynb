{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: Web scraping and text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook explains how to create a ML classification model to predict the author of the lyrics scraped from the website https://www.lyrics.com. The notebook was developed as as study project for the Spiced Academy Data Science Bootcamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping author 1 (Bob Dylan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Bob Dylan's songs\n",
    "url_dylan = 'https://www.lyrics.com/artist/Bob-Dylan/4147'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dylan = requests.get(url_dylan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the status of the request\n",
    "response_dylan.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_dylan = response_dylan.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_html_dylan = BeautifulSoup(html_dylan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_dylan = parsed_html_dylan.find_all('a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to format the artist's name as included in the lyrics' links\n",
    "# the name is inputed as a string and the white spaces are used to split the name\n",
    "\n",
    "def format_artist_name (name):\n",
    "    name_parts = name.split()\n",
    "    name_length = len(name_parts)\n",
    "    author_name = []\n",
    "    for x in range (0, name_length):\n",
    "        author_name.append(name_parts[x])\n",
    "    author_str =\"\"\n",
    "    result= \"+\".join(author_name, )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dylan = format_artist_name(\"Bob Dylan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the urls for the lyric webpages\n",
    "\n",
    "def get_lyric_url(links, artist):\n",
    "    artist_name = format_artist_name(artist)\n",
    "    \n",
    "    lyric_url_list = []\n",
    "    for link in links:\n",
    "        try:\n",
    "            if artist_name in link.get('href'):\n",
    "                part_url = link.get('href')\n",
    "                lyric_url_list.append(\"https://www.lyrics.com/track/\" + part_url[7:])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return lyric_url_list\n",
    "    \n",
    "       \n",
    "\n",
    "lyric_urls_dylan = get_lyric_url(links_dylan, \"Bob Dylan\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lyrics(lyric_urls, artist):\n",
    "    artist_name = format_artist_name(artist)\n",
    "    current_wd = os.getcwd()\n",
    "    new_d_name = artist_name.lower().replace(\"+\", \"_\")\n",
    "    artist_d = os.mkdir(current_wd+'/'+new_d_name)\n",
    "    \n",
    "    metadata = [[\"song_num\", \"song_title\"]]\n",
    "    for url in lyric_urls:\n",
    "        r = requests.get(url)\n",
    "        html_songpage = r.text\n",
    "        parsed_html_songpage = BeautifulSoup(html_songpage)\n",
    "        try:\n",
    "            song_title = parsed_html_songpage.find_all(\"h1\", attrs={'class': 'lyric-title'})[0].text\n",
    "            song_text = parsed_html_songpage.find_all(\"pre\")[0].text #, attrs={'class': 'lyric-body wselect-cnt'})\n",
    "            filename = re.search(\"\\d+\",url).group()\n",
    "            metadata_song = [filename,song_title]\n",
    "            metadata.append(metadata_song)\n",
    "            path = current_wd + '/'+ new_d_name + '/' + filename+\".txt\"\n",
    "        \n",
    "            with open(path, 'w') as file:\n",
    "                file.write(song_text)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    path_metadata = current_wd + '/'+ new_d_name + '/' + \"metadata\" + \".csv\"\n",
    "    with open(path_metadata, 'w') as csv_file:\n",
    "        csv_file_writer = csv.writer(csv_file)\n",
    "        csv_file_writer.writerows(metadata)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collecting Dylan's song lyrics\n",
    "dylan_lyrics = get_lyrics(lyric_urls_dylan, \"Bob Dylan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Web scraping author 2 (Bruce Springsteen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Bruce Springsteen's songs\n",
    "url_spreen = 'https://www.lyrics.com/artist/Bruce-Springsteen/5505'\n",
    "response_spreen = requests.get(url_spreen)\n",
    "html_spreen = response_spreen.text\n",
    "parsed_html_spreen = BeautifulSoup(html_spreen)\n",
    "links_spreen = parsed_html_spreen.find_all('a')\n",
    "holiday = format_artist_name(\"Bruce Springsteen\")\n",
    "lyric_urls_spreen = get_lyric_url(links_spreen, \"Bruce Springsteen\")\n",
    "spreen_lyrics = get_lyrics(lyric_urls_spreen, \"Bruce Springsteen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Bob Dylan's data in a df\n",
    "metadata_path_dylan = os.getcwd() + '/'+ \"bob_dylan\" + '/' + \"metadata.csv\"\n",
    "\n",
    "#Generating a dataframe for the songs metadata\n",
    "df_metadata_dylan = pd.read_csv(metadata_path_dylan)\n",
    "df_metadata_dylan['author']= 'Bob Dylan'\n",
    "\n",
    "#def read_metadata_author(author):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "song_num       int64\n",
      "song_title    object\n",
      "author        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_metadata_dylan.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_num</th>\n",
       "      <th>song_title</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36145301</td>\n",
       "      <td>Buckets of Rain</td>\n",
       "      <td>Bob Dylan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36145307</td>\n",
       "      <td>Idiot Wind</td>\n",
       "      <td>Bob Dylan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36145303</td>\n",
       "      <td>If You See Her, Say Hello</td>\n",
       "      <td>Bob Dylan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_num                 song_title     author\n",
       "0  36145301            Buckets of Rain  Bob Dylan\n",
       "1  36145307                 Idiot Wind  Bob Dylan\n",
       "2  36145303  If You See Her, Say Hello  Bob Dylan"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata_dylan.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "song_num        int64\n",
      "song_lyrics    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "txt_files = glob.glob(\"bob_dylan/*.txt\")\n",
    "current_wd = os.getcwd()\n",
    "\n",
    "lyrics_dict_dylan ={ }\n",
    "for file in txt_files:\n",
    "    filename = re.search(r\"\\d+\", file).group()\n",
    "    txt_filename = filename + \".txt\"\n",
    "    with open (os.path.join(current_wd,\"bob_dylan\", txt_filename), 'r+') as f:\n",
    "        lyrics = f.read()\n",
    "        lyrics_dict_dylan.update({filename:lyrics})\n",
    "        \n",
    "df_lyrics_dylan = pd.DataFrame.from_dict(lyrics_dict_dylan, orient='index').reset_index()\n",
    "df_lyrics_dylan.columns =[\"song_num\", \"song_lyrics\"]\n",
    "df_lyrics_dylan['song_num']= df_lyrics_dylan['song_num'].astype(np.int64)\n",
    "df_lyrics_dylan.head(3)\n",
    "print(df_lyrics_dylan.dtypes)\n",
    "\n",
    "\n",
    "\n",
    "#def read_file_content(txt_folder):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6546, 4)\n"
     ]
    }
   ],
   "source": [
    "df_dylan = df_metadata_dylan.merge(df_lyrics_dylan)\n",
    "\n",
    "df_dylan.head(3)\n",
    "print(df_dylan.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "song_num        int64\n",
      "song_lyrics    object\n",
      "dtype: object\n",
      "(2706, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_num</th>\n",
       "      <th>song_title</th>\n",
       "      <th>author</th>\n",
       "      <th>song_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36456915</td>\n",
       "      <td>Dancing in the Dark</td>\n",
       "      <td>Bruce Springsteen</td>\n",
       "      <td>I get up in the evenin'\\nAnd I ain't got nothi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36456910</td>\n",
       "      <td>Badlands</td>\n",
       "      <td>Bruce Springsteen</td>\n",
       "      <td>Lights out tonight\\nTrouble in the heartland\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36456909</td>\n",
       "      <td>Cover Me</td>\n",
       "      <td>Bruce Springsteen</td>\n",
       "      <td>The times are tough now, just getting tougher\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_num           song_title             author  \\\n",
       "0  36456915  Dancing in the Dark  Bruce Springsteen   \n",
       "1  36456910             Badlands  Bruce Springsteen   \n",
       "2  36456909             Cover Me  Bruce Springsteen   \n",
       "\n",
       "                                         song_lyrics  \n",
       "0  I get up in the evenin'\\nAnd I ain't got nothi...  \n",
       "1  Lights out tonight\\nTrouble in the heartland\\n...  \n",
       "2  The times are tough now, just getting tougher\\...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the Bruce Springsteen's data in a df\n",
    "metadata_path_spreen = os.getcwd() + '/'+ \"bruce_springsteen\" + '/' + \"metadata.csv\"\n",
    "df_metadata_spreen = pd.read_csv(metadata_path_spreen)\n",
    "df_metadata_spreen['author']= 'Bruce Springsteen'\n",
    "txt_files = glob.glob(\"bruce_springsteen/*.txt\")\n",
    "current_wd = os.getcwd()\n",
    "\n",
    "lyrics_dict_spreen ={ }\n",
    "for file in txt_files:\n",
    "    filename = re.search(r\"\\d+\", file).group()\n",
    "    txt_filename = filename + \".txt\"\n",
    "    with open (os.path.join(current_wd,\"bruce_springsteen\", txt_filename), 'r+') as f:\n",
    "        lyrics = f.read()\n",
    "        lyrics_dict_spreen.update({filename:lyrics})\n",
    "        \n",
    "df_lyrics_spreen = pd.DataFrame.from_dict(lyrics_dict_spreen, orient='index').reset_index()\n",
    "df_lyrics_spreen.columns =[\"song_num\", \"song_lyrics\"]\n",
    "df_lyrics_spreen['song_num']= df_lyrics_spreen['song_num'].astype(np.int64)\n",
    "df_lyrics_spreen.head(3)\n",
    "\n",
    "print(df_lyrics_spreen.dtypes)\n",
    "df_spreen = df_metadata_spreen.merge(df_lyrics_spreen)\n",
    "print(df_spreen.shape)\n",
    "df_spreen.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the two authors dataframes\n",
    "df = pd.concat([df_dylan, df_spreen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop([\"author\"], axis=1), df[\"author\"],\n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_num</th>\n",
       "      <th>song_title</th>\n",
       "      <th>song_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4756</th>\n",
       "      <td>22184408</td>\n",
       "      <td>Jokerman</td>\n",
       "      <td>Standing on the waters casting your bread\\nWhi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>21226112</td>\n",
       "      <td>The Times They Are a-Changin'</td>\n",
       "      <td>Come gather 'round people\\nWherever you roam\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5278</th>\n",
       "      <td>772620</td>\n",
       "      <td>Emotionally Yours</td>\n",
       "      <td>Come baby, find me, come baby, remind me of wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      song_num                     song_title  \\\n",
       "4756  22184408                       Jokerman   \n",
       "2302  21226112  The Times They Are a-Changin'   \n",
       "5278    772620              Emotionally Yours   \n",
       "\n",
       "                                            song_lyrics  \n",
       "4756  Standing on the waters casting your bread\\nWhi...  \n",
       "2302  Come gather 'round people\\nWherever you roam\\n...  \n",
       "5278  Come baby, find me, come baby, remind me of wh...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['cleaned_lyric'] = X_train['song_lyrics'].str.replace(\"\\d+|\\n|[.,:;!?]|\\s\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = X_train['cleaned_lyric'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/giudittaparolini/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/giudittaparolini/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stopwords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stopwords = nltk_stopwords+['aa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list = [word_tokenize(text) for text in text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tokens = []\n",
    "for text in tokens_list:\n",
    "    cleaned_tokens_subl = []\n",
    "    for token in text:\n",
    "        if (token not in my_stopwords) and (len(token)>3):\n",
    "            cleaned_tokens_subl.append(token)\n",
    "    cleaned_tokens.append(cleaned_tokens_subl)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tokens_str_format = []\n",
    "for element in cleaned_tokens:\n",
    "    my_str = \" \".join(map(str, element))\n",
    "    cleaned_tokens_str_format.append(my_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['cleaned_lyric'] = pd.Series(data=cleaned_tokens_str_format, index = X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['cleaned_lyric'] = X_train['cleaned_lyric'].astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_num          int64\n",
       "song_title       object\n",
       "song_lyrics      object\n",
       "cleaned_lyric    string\n",
       "dtype: object"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4756    Bob Dylan\n",
       "2302    Bob Dylan\n",
       "5278    Bob Dylan\n",
       "Name: author, dtype: object"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cleaned_lyrics = X_train['cleaned_lyric'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Standing waters casting bread While eyes idol iron head glowing Distant ships sailing mist born snake fists hurricane blowing Freedom around corner truth good Jokerman dance nightingale tune Bird high light moon Jokerman swiftly sets rise goodbye Fools rush angels fear tread Both futures full dread show Shedding layer skin Keeping step ahead persecutor within Jokerman dance nightingale tune Bird high light moon Jokerman mountains walk clouds Manipulator crowds dream twister going Sodom Gomorrah care nobody would want marry sister Friend martyr friend woman shame look fiery furnace rich without name Jokerman dance nightingale tune Bird high light moon Jokerman Well Book Leviticus Deuteronomy jungle teachers smoke twilight milk-white steed Michelangelo indeed could carved features Resting fields turbulent space Half asleep near stars small licking face Jokerman dance nightingale tune Bird high light moon Jokerman Well rifleman stalking sick lame Preacherman seeks first uncertain Nightsticks water cannons tear padlocks Molotov cocktails rocks behind every curtain False-hearted judges dying webs spin Only matter time 'til night comes steppin Jokerman dance nightingale tune Bird high light moon Jokerman shadowy world skies slippery gray woman gave birth prince today dressed scarlet priest pocket blade heat Take motherless children street place feet harlot Jokerman know wants Jokerman show response Jokerman dance nightingale tune Bird high light moon Jokerman\""
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_cleaned_lyrics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = y_train.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vect', CountVectorizer(lowercase=False)),\n",
    "                     ('tfidf', TfidfVectorizer(lowercase=False))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=False, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=No...\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=False, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-277-7184c55e70c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_cleaned_lyrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/testenv/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/testenv/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1857\u001b[0m         \"\"\"\n\u001b[1;32m   1858\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1859\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1860\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/testenv/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1220\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/testenv/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/testenv/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "X = pipeline.fit_transform(list_cleaned_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7401, 12631)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12621</th>\n",
       "      <th>12622</th>\n",
       "      <th>12623</th>\n",
       "      <th>12624</th>\n",
       "      <th>12625</th>\n",
       "      <th>12626</th>\n",
       "      <th>12627</th>\n",
       "      <th>12628</th>\n",
       "      <th>12629</th>\n",
       "      <th>12630</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bob Dylan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bob Dylan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bob Dylan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bob Dylan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bob Dylan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bob Dylan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bob Dylan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bob Dylan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bob Dylan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bruce Springsteen</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7401 rows Ã— 12631 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0      1      2      3      4      5      6      7      \\\n",
       "Bob Dylan            0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "Bob Dylan            0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "Bob Dylan            0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "Bob Dylan            0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "Bob Dylan            0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...                  ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "Bob Dylan            0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "Bob Dylan            0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "Bob Dylan            0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "Bob Dylan            0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "Bruce Springsteen    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "                   8      9      ...  12621  12622  12623  12624  12625  \\\n",
       "Bob Dylan            0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "Bob Dylan            0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "Bob Dylan            0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "Bob Dylan            0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "Bob Dylan            0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "...                  ...    ...  ...    ...    ...    ...    ...    ...   \n",
       "Bob Dylan            0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "Bob Dylan            0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "Bob Dylan            0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "Bob Dylan            0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "Bruce Springsteen    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "                   12626  12627  12628  12629  12630  \n",
       "Bob Dylan            0.0    0.0    0.0    0.0    0.0  \n",
       "Bob Dylan            0.0    0.0    0.0    0.0    0.0  \n",
       "Bob Dylan            0.0    0.0    0.0    0.0    0.0  \n",
       "Bob Dylan            0.0    0.0    0.0    0.0    0.0  \n",
       "Bob Dylan            0.0    0.0    0.0    0.0    0.0  \n",
       "...                  ...    ...    ...    ...    ...  \n",
       "Bob Dylan            0.0    0.0    0.0    0.0    0.0  \n",
       "Bob Dylan            0.0    0.0    0.0    0.0    0.0  \n",
       "Bob Dylan            0.0    0.0    0.0    0.0    0.0  \n",
       "Bob Dylan            0.0    0.0    0.0    0.0    0.0  \n",
       "Bruce Springsteen    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[7401 rows x 12631 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X.todense(), index=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression().fit(X, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9867585461424132"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['cleaned_lyric'] = X_test['song_lyrics'].str.replace(\"\\d+|\\n|[.,:;!?]|\\s\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list_test = X_test['cleaned_lyric'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list_test = [word_tokenize(text) for text in text_list_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tokens_test = []\n",
    "for text in tokens_list_test:\n",
    "    cleaned_tokens_subl = []\n",
    "    for token in text:\n",
    "        if (token not in my_stopwords) and (len(token)>3):\n",
    "            cleaned_tokens_subl.append(token)\n",
    "    cleaned_tokens_test.append(cleaned_tokens_subl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tokens_str_format_test = []\n",
    "for element in cleaned_tokens_test:\n",
    "    my_str = \" \".join(map(str, element))\n",
    "    cleaned_tokens_str_format_test.append(my_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['cleaned_lyric'] = pd.Series(data=cleaned_tokens_str_format_test, index = X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cleaned_lyrics_test = X_test['cleaned_lyric'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = pipeline.transform(list_cleaned_lyrics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1851, 12631)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model.predict(X_test_transformed)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9681253376553215"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.978954</td>\n",
       "      <td>0.021046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.935657</td>\n",
       "      <td>0.064343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.234201</td>\n",
       "      <td>0.765799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.053787</td>\n",
       "      <td>0.946213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.942964</td>\n",
       "      <td>0.057036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>0.961473</td>\n",
       "      <td>0.038527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>0.953887</td>\n",
       "      <td>0.046113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>0.970938</td>\n",
       "      <td>0.029062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>0.299031</td>\n",
       "      <td>0.700969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>0.830431</td>\n",
       "      <td>0.169569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1851 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1\n",
       "0     0.978954  0.021046\n",
       "1     0.935657  0.064343\n",
       "2     0.234201  0.765799\n",
       "3     0.053787  0.946213\n",
       "4     0.942964  0.057036\n",
       "...        ...       ...\n",
       "1846  0.961473  0.038527\n",
       "1847  0.953887  0.046113\n",
       "1848  0.970938  0.029062\n",
       "1849  0.299031  0.700969\n",
       "1850  0.830431  0.169569\n",
       "\n",
       "[1851 rows x 2 columns]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "\n",
    "probs = model.predict_proba(X_test_transformed)  \n",
    "pd.DataFrame(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
